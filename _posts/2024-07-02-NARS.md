---
layout: post
title: Negative Attitudes Towards Robots Scale
category: "attitudes"
pubyear: 2006
pubauthor: nomura
scalename: NARS
---

**NOTE: THIS IS NOT THE LATEST VERSION OF THIS SCALE.** 

# Construct Summary

The authors define the construct of negative attitudes towards robots as follows:

>"In considering negative attitudes toward robots, we need to take into account two psychological constructs related to it, which will be components of negative attitudes toward robots. One is the computer anxiety mentioned above, and the other is communication apprehension." (p 440)

They define computer anxiety as follows:

>"...considered to be anxiety or apprehension evoked in individuals when they use computers, do things leading them to computers, or think about the meaning of computers." (p. 440)

They define communication apprehension as follows:

>"...as a level of fear or anxiety in individuals toward real communication with another or others and prediction of it, such as speech, writing, singing, and so on." (p. 441)

The authors define attitudes as follows:

>"It is defined as a relatively stable and enduring predisposition to behave or react in a certain way toward persons, objects, institutions, or issues, and the source is cultural, familial, and personal." (p. 440)


# Rating = 69%

<table>
  <thead>
    <tr>
      <th>Check?</th>
      <th>Guideline Item</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>&#10003;</td>
      <td>Is the construct defined?</td>
    </tr>
    <tr>
      <td>&#10003;</td>
      <td>Does the final version of the items capture the construct as it has been defined by the authors?</td>
    </tr>
    <tr>
      <td>&#10003;</td>
      <td>Is the item generation process discussed (e.g., literature review, Delphi method, crowd-sourcing)?</td>
    </tr>
    <tr>
      <td style="color: red;">&#10006;</td>
      <td>Person to items 10:1 for the initial set of items?</td>
    </tr>
    <tr>
      <td>&#10003;</td>
      <td>Did they perform an EFA, PCA, Rasch, or similar test to determine the item to factor relationship?</td>
    </tr>
    <tr>
      <td>&#10003;</td>
      <td>Did they describe how they determined number of factors?</td>
    </tr>
    <tr>
      <td style="color: red;">&#10006;</td>
      <td>Did they report the full initial set of items?</td>
    </tr>
    <tr>
      <td style="color: red;">&#10006;</td>
      <td>Did they provide loadings (EFA) or item fits (Rasch) of all items?</td>
    </tr>
    <tr>
      <td style="color: red;">&#10006;</td>
      <td>Is there a description of the item removal process (e.g., using infit/outfit, factor loading minimum value, or cross-loading values)?</td>
    </tr>
    <tr>
      <td>&#10003;</td>
      <td>Did they list the final items included in the scale?</td>
    </tr>
    <tr>
      <td>&#10003;</td>
      <td>Did they include a factor structure test (e.g., second EFA, CFA, DIF, test for unidimensionality when using Rasch, or similar)?</td>
    </tr>
    <tr>
      <td>&#10003;</td>
      <td>Was a measure of reliability (e.g., Cronbach’s alpha, McDonalds Omega_h or Omega_t, Tarkkonen’s Rho) reported?</td>
    </tr>
    <tr>
      <td>&#10003;</td>
      <td>Was a test of validity (e.g., predictive, concurrent, convergent, discriminant) reported?</td>
    </tr>
  </tbody>
</table>

**Comments**
None

# Reviewed by Experts &#10003;


# Downloads
[PAPER](https://www.jbe-platform.com/content/journals/10.1075/is.7.3.14nom){:target="_blank"}
<br>Nomura, T., Suzuki, T., Kanda, T., & Kato, K. (2006). Measurement of negative attitudes toward robots. Interaction Studies. Social Behaviour and Communication in Biological and Artificial Systems, 7(3), 437-454.

<br>PDF of scale as well as instructions for administration and scoring are not readily available. Check the paper for more details or email hriscaledatabase@gmail.com to submit this information if you are the author of this scale.

# Final Scale Items (14):

I would feel uneasy if robots really had emotions.
<br>Something bad might happen if robots developed into living beings.
<br>I would feel relaxed talking with robots.
<br>I would feel uneasy if I was given a job where I had to use robots.
<br>If robots had emotions, I would be able to make friends with them.
<br>I feel comforted being with robots that have emotions.
<br>The word "robot" means nothing to me.
<br>I would feel nervous operating a robot in front of other people.
<br>I would have the idea that robots or artificial intelligences were making judgments about things.
<br>I would feel very nervous just standing in front of a robot.
<br>I feel that if I depend on robots too much, something bad might happen.
<br>I would feel paranoid talking with a robot.
<br>I am concerned that robots would be a bad influence on children.
<br>I feel that in the future society will be dominated by robots.