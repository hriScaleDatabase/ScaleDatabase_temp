---
layout: post
title: Partner Modeling Questionnaire (PMQ)
category: "social"
pubyear: 2023
pubauthor: Doyle et al.
scalename: PMQ
---

**This is the most up to date version of this scale.**

# Construct Summary

The authors report that the scale is designed to measure people's partner models of non-embodied speech interfaces. The scale consists of three dimensions:

>"[The first dimension is] perceived competence and dependability in communication, which stems from a focus on communicative attributes including but not limited to, competence, dependability, reliability, consistency and efficiency. The next dimension is human-likeness in communication, which stems from broad human-machine comparisons, perceptions of a system’s capacity for warmth and empathy, and how social-transactional interactions feel. Finally, the work identified perceived communicative flexibility as an important partner model dimension that stems from a concern with how flexible or spontaneous a system appears to be in dialogue, and its capacity for interpretation." (p. 28)
 

# Rating = 69% 

<table>
  <thead>
    <tr>
      <th>Check?</th>
      <th>Guideline Item</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>&#10003;</td>
      <td>Is the construct defined?</td>
    </tr>
    <tr>
      <td>&#10003;</td>
      <td>Does the final version of the items capture the construct as it has been defined by the authors?</td>
    </tr>
    <tr>
      <td>&#10003;</td>
      <td>Is the item generation process discussed (e.g., literature review, Delphi method, crowd-sourcing)?</td>
    </tr>
    <tr>
      <td style="color: red;">&#10006;</td>
      <td>Person to items 10:1 for the initial set of items?</td>
    </tr>
    <tr>
      <td>&#10003;</td>
      <td>Did they perform an EFA, PCA, Rasch, or similar test to determine the item to factor relationship?</td>
    </tr>
    <tr>
      <td>&#10003;</td>
      <td>Did they describe how they determined number of factors?</td>
    </tr>
    <tr>
      <td style="color: red;">&#10006;</td>
      <td>Did they report the full initial set of items?</td>
    </tr>
    <tr>
      <td style="color: red;">&#10006;</td>
      <td>Did they provide loadings (EFA) or item fits (Rasch) of all items?</td>
    </tr>
    <tr>
      <td>&#10003;</td>
      <td>Is there a description of the item removal process (e.g., using infit/outfit, factor loading minimum value, or cross-loading values)?</td>
    </tr>
    <tr>
      <td style="color: red;">&#10006;</td>
      <td>Did they list the final items included in the scale?</td>
    </tr>
    <tr>
      <td>&#10003;</td>
      <td>Did they include a factor structure test (e.g., second EFA, CFA, DIF, test for unidimensionality when using Rasch, or similar)?</td>
    </tr>
    <tr>
      <td>&#10003;</td>
      <td>Was a measure of reliability (e.g., Cronbach’s alpha, McDonalds Omega_h or Omega_t, Tarkkonen’s Rho) reported?</td>
    </tr>
    <tr>
      <td>&#10003;</td>
      <td>Was a test of validity (e.g., predictive, concurrent, convergent, discriminant) reported?</td>
    </tr>
  </tbody>
</table>

**Comments**
The specific items contained within the 18 item version was not clearly specified in paper. The eliminated items from the 23 item version were specified in text only. 

# Reviewed by Experts &#10003;


# Downloads
[PAPER](https://arxiv.org/abs/2308.07164){:target="_blank"}
<br>Doyle, P. R., Gessinger, I., Edwards, J., Clark, L., Dumbleton, O., Garaialde, D., ... & Cowan, B. R. (2023). The Partner Modelling Questionnaire: A validated self-report measure of perceptions toward machines as dialogue partners. arXiv preprint arXiv:2308.07164.

<br>PDF of scale as well as instructions for administration and scoring are not readily available. Check the paper for more details or email hriscaledatabase@gmail.com submit this information if you are the author of this scale.

# Final Scale Items (18 total):

Unclear